# -*- coding: utf-8 -*-
"""config.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B_Wn-RYDooK5UgOb4-eJfALpeXDBEGBA
"""

# config.py
class Config(object):
    N = 1 #6 in Transformer Paper
    d_model = 768 #512 in Transformer Paper
    d_ff = 768 #2048 in Transformer Paper
    embed_size=300
    h = 6
    dropout = 0.10
    output_size = 1
    lr = 0.00005
    max_epochs = 3
    batch_size = 32
    max_sen_len = 50
    acc=0 #1 for msrp, 0 for trec
    multiplyby=100
    hidden_layers = 2
    hidden_size = 768
    bidirectional = True
    dropout_keep = 0.1
    model=0 #0 for transformerEncoderbase, 1 for blstm
    #emb="../data/bert"
    EmbeddingType = "Contextualized" #Otherwise, EmbeddingType="Contextualized" or "Baseline"

    data = "trecr"
    dataraw = "D:/2021/AS2experiment/AS2/model_Transformer/dataSetRaw/TRECR/"
    trainpath = "D:/2021/AS2experiment/AS2/model_Transformer/dataSet/train/"
    validpath = "D:/2021/AS2experiment/AS2/model_Transformer/dataSet/valid/"
    testpath = "D:/2021/AS2experiment/AS2/model_Transformer/dataSet/test/"

    #emb = "D:/2021/AS2experiment/AS2/model_Transformer/dataSet/"



    # trecc 0.405 0.476
    # wiki 0.566 0.571
    # YAHOO 0.436, 0.436
    # semeval2016 0.604, 0.670
    # semeval2017 0.700 0.757